{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee8507f4-fcb5-4063-a35b-09b5f4d5f092",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import Data, HeteroData\n",
    "from torch_geometric.typing import EdgeType\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from typing import Union, Optional, List\n",
    "from copy import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f698802-81c2-478c-a0ec-611039a2d28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons = [18, 19, 20, 21, 22]\n",
    "players_df = pd.read_csv(\"player_data/player_data.csv\")\n",
    "matches_df = pd.read_csv(\"match_data/match_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cff21198-8c9a-47a2-8293-60a1557aa7ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Define player club position\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#position_cols = [x for x in players_df.columns if \"club_position_\" in x]\u001b[39;00m\n\u001b[0;32m      3\u001b[0m positions \u001b[38;5;241m=\u001b[39m players_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclub_position\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39munique()\n\u001b[1;32m----> 4\u001b[0m player_club_position \u001b[38;5;241m=\u001b[39m \u001b[43mplayers_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclub_position\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpositions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[0;32m      5\u001b[0m player_club_position \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(player_club_position)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(player_club_position)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\harvard\\lib\\site-packages\\pandas\\core\\series.py:4357\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4248\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4249\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4252\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4253\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FrameOrSeriesUnion:\n\u001b[0;32m   4254\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4255\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4256\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4355\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4356\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4357\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\harvard\\lib\\site-packages\\pandas\\core\\apply.py:1043\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1040\u001b[0m     \u001b[38;5;66;03m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[1;32m-> 1043\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\harvard\\lib\\site-packages\\pandas\\core\\apply.py:1098\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1092\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m   1093\u001b[0m         \u001b[38;5;66;03m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m         \u001b[38;5;66;03m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[0;32m   1095\u001b[0m         \u001b[38;5;66;03m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[0;32m   1096\u001b[0m         \u001b[38;5;66;03m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m         \u001b[38;5;66;03m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[1;32m-> 1098\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1099\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1100\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1101\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1102\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1105\u001b[0m     \u001b[38;5;66;03m# GH 25959 use pd.array instead of tolist\u001b[39;00m\n\u001b[0;32m   1106\u001b[0m     \u001b[38;5;66;03m# so extension arrays can be used\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(pd_array(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\harvard\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2859\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[6], line 4\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Define player club position\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#position_cols = [x for x in players_df.columns if \"club_position_\" in x]\u001b[39;00m\n\u001b[0;32m      3\u001b[0m positions \u001b[38;5;241m=\u001b[39m players_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclub_position\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39munique()\n\u001b[1;32m----> 4\u001b[0m player_club_position \u001b[38;5;241m=\u001b[39m players_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclub_position\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mpositions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m(x))\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[0;32m      5\u001b[0m player_club_position \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(player_club_position)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(player_club_position)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'index'"
     ]
    }
   ],
   "source": [
    "# Define player club position\n",
    "#position_cols = [x for x in players_df.columns if \"club_position_\" in x]\n",
    "positions = players_df[\"club_position\"].unique()\n",
    "player_club_position = players_df[\"club_position\"].apply(lambda x: positions.index(x)).to_numpy()\n",
    "player_club_position = torch.from_numpy(player_club_position).to(torch.float)\n",
    "print(player_club_position)\n",
    "print(\"Player Position Size\")\n",
    "print(\"====================\")\n",
    "print (player_club_position.size())   # 29 possible positions.\n",
    "\n",
    "# Define player features:\n",
    "player_feat = players_df.drop(columns=position_cols+[\"sofifa_id\", \"club_name\"])\n",
    "player_feat = player_feat.to_numpy(dtype=\"float64\")\n",
    "player_feat = torch.from_numpy(player_feat).to(torch.float)\n",
    "print(player_feat)\n",
    "print(\"Player Feature Size\")\n",
    "print(\"====================\")\n",
    "print (player_feat.size())   # 223 features in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e556d5c3-1ddb-4ae3-81f7-e60db6c435b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 1,  ..., 0, 0, 0],\n",
      "        [1, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 1,  ..., 0, 0, 0],\n",
      "        [0, 0, 1,  ..., 0, 0, 0]])\n",
      "\n",
      "Match Feature Size\n",
      "====================\n",
      "torch.Size([23457, 15])\n",
      "\n",
      "tensor([[18,  1],\n",
      "        [18,  1],\n",
      "        [18,  1],\n",
      "        ...,\n",
      "        [22, 38],\n",
      "        [22, 38],\n",
      "        [22, 38]], dtype=torch.int32)\n",
      "\n",
      "Match Info Size\n",
      "====================\n",
      "torch.Size([23457, 2])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define match features\n",
    "feature_cols = [\"FTHG\", \"FTAG\", \"HS\", \"AS\", \"HST\", \"AST\", \"HC\", \"AC\", \"HY\", \"AY\", \"HR\", \"AR\"]\n",
    "match_result = matches_df[\"FTR\"].str.get_dummies()\n",
    "match_feat = pd.concat((match_result, matches_df[feature_cols]), axis=1).to_numpy()\n",
    "match_feat = torch.from_numpy(match_feat).to(torch.long)\n",
    "print(match_feat)\n",
    "print()\n",
    "print(\"Match Feature Size\")\n",
    "print(\"====================\")\n",
    "print (match_feat.size())   # 3 results columns + 12 different match statistics.\n",
    "print()\n",
    "\n",
    "# Define match results:\n",
    "#match_result = matches_df[\"FTR\"].str.get_dummies().to_numpy()\n",
    "#match_result = torch.from_numpy(match_result).to(torch.long)\n",
    "#print(match_result)\n",
    "#print()\n",
    "#print(\"Match Result Size\")\n",
    "#print(\"====================\")\n",
    "#print (match_result.size())   # 3 possible results: Home win, Away win, Draw.\n",
    "#print()\n",
    "\n",
    "# Define match infos\n",
    "info_cols = [\"Season\", \"Week\"]\n",
    "match_info = matches_df[info_cols].to_numpy()\n",
    "match_info = torch.from_numpy(match_info).to(torch.int)\n",
    "print(match_info)\n",
    "print()\n",
    "print(\"Match Info Size\")\n",
    "print(\"====================\")\n",
    "print (match_info.size())   # 2 different types of information.\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca38e250-e8b9-452d-9848-dfa87beed9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping of player IDs to consecutive values:\n",
      "==========================================\n",
      "    playerId  mappedID\n",
      "0   18_20801         0\n",
      "1  18_158023         1\n",
      "2  18_167495         2\n",
      "3  18_176580         3\n",
      "4  18_190871         4\n",
      "\n",
      "Mapping of club IDs to consecutive values:\n",
      "===========================================\n",
      "  clubId  mappedID\n",
      "0   18_1         0\n",
      "1   18_2         1\n",
      "2   18_3         2\n",
      "3   18_4         3\n",
      "4   18_5         4\n"
     ]
    }
   ],
   "source": [
    "# Create a mapping from unique player indices to range [0, num_player_nodes):\n",
    "players_df[\"PlayerID\"] = players_df.apply(lambda row: str(row.season) + \"_\" + str(row.sofifa_id), axis=1)\n",
    "unique_player_id = pd.DataFrame(data={\n",
    "    'playerId': players_df[\"PlayerID\"],\n",
    "    'mappedID': pd.RangeIndex(len(players_df[\"PlayerID\"])),\n",
    "})\n",
    "print(\"Mapping of player IDs to consecutive values:\")\n",
    "print(\"==========================================\")\n",
    "print(unique_player_id.head())\n",
    "print()\n",
    "\n",
    "# Replace team names with unique team IDs\n",
    "team_ids = list(players_df[\"club_name\"].unique())\n",
    "team_season_ids = list(players_df.apply(lambda row: str(row.season) + \"_\" + str(team_ids.index(row.club_name) + 1), axis=1).unique())\n",
    "players_df[\"club_id\"] = players_df.apply(lambda row: str(row.season) + \"_\" + str(team_ids.index(row.club_name) + 1), axis=1)\n",
    "matches_df[\"HomeID\"] = matches_df.apply(lambda row: str(row.Season) + \"_\" + str(team_ids.index(row.HomeTeam) + 1), axis=1)\n",
    "matches_df[\"AwayID\"] = matches_df.apply(lambda row: str(row.Season) + \"_\" + str(team_ids.index(row.AwayTeam) + 1), axis=1)\n",
    "\n",
    "# Create a mapping from unique club indices to range [0, num_match_nodes):\n",
    "matches_df['MatchID'] = matches_df.apply(lambda row: str(row.Season) + \"_\" + str(team_ids.index(row.HomeTeam) + 1) + \"_\" + str(team_ids.index(row.AwayTeam) + 1), axis=1)\n",
    "unique_club_id = pd.DataFrame(data={\n",
    "    'clubId': team_season_ids,\n",
    "    'mappedID': pd.RangeIndex(len(team_season_ids)),\n",
    "})\n",
    "print(\"Mapping of club IDs to consecutive values:\")\n",
    "print(\"===========================================\")\n",
    "print(unique_club_id.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "877c7970-c5c8-40a3-a476-d66b7b9212df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Player_club_id:\n",
      "=================================================\n",
      "tensor([    0,     1,     2,  ..., 36816, 36817, 36818])\n",
      "\n",
      "Club_player_id:\n",
      "=================================================\n",
      "tensor([   0,    1,    2,  ..., 1239, 1211, 1197])\n",
      "\n",
      "Final edge indices pointing from players to clubs:\n",
      "=================================================\n",
      "tensor([[    0,     1,     2,  ..., 36816, 36817, 36818],\n",
      "        [    0,     1,     2,  ...,  1239,  1211,  1197]])\n"
     ]
    }
   ],
   "source": [
    "# Perform merge to obtain the edges from players and clubs:\n",
    "player_club_id = torch.from_numpy(unique_player_id['mappedID'].values)\n",
    "club_player_id = pd.merge(players_df['club_id'], unique_club_id,\n",
    "                            left_on='club_id', right_on='clubId', how='left')\n",
    "club_player_id = torch.from_numpy(club_player_id['mappedID'].values)\n",
    "\n",
    "print()\n",
    "print(\"Player_club_id:\")\n",
    "print(\"=================================================\")\n",
    "print(player_club_id)\n",
    "print()\n",
    "print(\"Club_player_id:\")\n",
    "print(\"=================================================\")\n",
    "print(club_player_id)\n",
    "\n",
    "# With this, we are ready to construct our `edge_index` in COO format\n",
    "# following PyG semantics:\n",
    "edge_index_player_to_club = torch.stack([player_club_id, club_player_id], dim=0)\n",
    "assert edge_index_player_to_club.size() == (2, len(player_club_id))\n",
    "\n",
    "print()\n",
    "print(\"Final edge indices pointing from players to clubs:\")\n",
    "print(\"=================================================\")\n",
    "print(edge_index_player_to_club)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49fa7f67-5816-4712-99c4-acd1ddd66492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Home_club_id:\n",
      "=================================================\n",
      "tensor([ 109,  190,  172,  ..., 1080, 1112, 1192])\n",
      "\n",
      "Away_club_id:\n",
      "=================================================\n",
      "tensor([  92,  194,  198,  ..., 1146, 1183, 1246])\n",
      "\n",
      "Final edge indices pointing from home to away teams:\n",
      "=================================================\n",
      "tensor([[ 109,  190,  172,  ..., 1080, 1112, 1192],\n",
      "        [  92,  194,  198,  ..., 1146, 1183, 1246]])\n"
     ]
    }
   ],
   "source": [
    "# Perform merge to obtain the edges from home teams to away teams:\n",
    "home_club_id = pd.merge(matches_df['HomeID'], unique_club_id,\n",
    "                            left_on='HomeID', right_on='clubId', how='left')\n",
    "home_club_id = torch.from_numpy(home_club_id['mappedID'].values)\n",
    "away_club_id = pd.merge(matches_df['AwayID'], unique_club_id,\n",
    "                            left_on='AwayID', right_on='clubId', how='left')\n",
    "away_club_id = torch.from_numpy(away_club_id['mappedID'].values)\n",
    "\n",
    "print()\n",
    "print(\"Home_club_id:\")\n",
    "print(\"=================================================\")\n",
    "print(home_club_id)\n",
    "print()\n",
    "print(\"Away_club_id:\")\n",
    "print(\"=================================================\")\n",
    "print(away_club_id)\n",
    "\n",
    "\n",
    "# With this, we are ready to construct our `edge_index` in COO format\n",
    "# following PyG semantics:\n",
    "edge_index_club_to_club = torch.stack([home_club_id, away_club_id], dim=0)\n",
    "assert edge_index_club_to_club.size() == (2, len(matches_df))\n",
    "\n",
    "print()\n",
    "print(\"Final edge indices pointing from home to away teams:\")\n",
    "print(\"=================================================\")\n",
    "print(edge_index_club_to_club)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27cd3dd6-9338-4972-adec-8694092839fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinkSplit(RandomLinkSplit):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_val: Union[int, float] = 0.1,\n",
    "        num_test: Union[int, float] = 0.2,\n",
    "        is_undirected: bool = False,\n",
    "        key: str = 'edge_label',\n",
    "        split_labels: bool = False,\n",
    "        add_negative_train_samples: bool = True,\n",
    "        neg_sampling_ratio: float = 1.0,\n",
    "        disjoint_train_ratio: Union[int, float] = 0.0,\n",
    "        edge_types: Optional[Union[EdgeType, List[EdgeType]]] = None,\n",
    "        rev_edge_types: Optional[Union[EdgeType, List[EdgeType]]] = None,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            num_val,\n",
    "            num_test,\n",
    "            is_undirected,\n",
    "            key,\n",
    "            split_labels,\n",
    "            add_negative_train_samples,\n",
    "            neg_sampling_ratio,\n",
    "            disjoint_train_ratio,\n",
    "            edge_types,\n",
    "            rev_edge_types\n",
    "        )\n",
    "    def __call__(self, data: Union[Data, HeteroData]) -> Union[Data, HeteroData]:\n",
    "        edge_types = self.edge_types\n",
    "        rev_edge_types = self.rev_edge_types\n",
    "\n",
    "        train_data, val_data, test_data = copy(data), copy(data), copy(data)\n",
    "\n",
    "        if isinstance(data, HeteroData):\n",
    "            if edge_types is None:\n",
    "                raise ValueError(\n",
    "                    \"The 'RandomLinkSplit' transform expects 'edge_types' to \"\n",
    "                    \"be specified when operating on 'HeteroData' objects\")\n",
    "\n",
    "            if not isinstance(edge_types, list):\n",
    "                edge_types = [edge_types]\n",
    "                rev_edge_types = [rev_edge_types]\n",
    "\n",
    "            stores = [data[edge_type] for edge_type in edge_types]\n",
    "            train_stores = [train_data[edge_type] for edge_type in edge_types]\n",
    "            val_stores = [val_data[edge_type] for edge_type in edge_types]\n",
    "            test_stores = [test_data[edge_type] for edge_type in edge_types]\n",
    "        else:\n",
    "            rev_edge_types = [None]\n",
    "            stores = [data._store]\n",
    "            train_stores = [train_data._store]\n",
    "            val_stores = [val_data._store]\n",
    "            test_stores = [test_data._store]\n",
    "\n",
    "        for item in zip(stores, train_stores, val_stores, test_stores,\n",
    "                        rev_edge_types):\n",
    "            store, train_store, val_store, test_store, rev_edge_type = item\n",
    "\n",
    "            is_undirected = self.is_undirected\n",
    "            is_undirected &= not store.is_bipartite()\n",
    "            is_undirected &= (rev_edge_type is None\n",
    "                              or store._key == data[rev_edge_type]._key)\n",
    "\n",
    "            edge_index = store.edge_index\n",
    "            if is_undirected:\n",
    "                mask = edge_index[0] <= edge_index[1]\n",
    "                perm = mask.nonzero(as_tuple=False).view(-1)\n",
    "                perm = perm[torch.randperm(perm.size(0), device=perm.device)]\n",
    "            else:\n",
    "                device = edge_index.device\n",
    "                #perm = torch.randperm(edge_index.size(1), device=device)\n",
    "                perm = torch.arange(start=0, end=edge_index.size(1), device=device)\n",
    "\n",
    "            num_val = self.num_val\n",
    "            if isinstance(num_val, float):\n",
    "                num_val = int(num_val * perm.numel())\n",
    "            num_test = self.num_test\n",
    "            if isinstance(num_test, float):\n",
    "                num_test = int(num_test * perm.numel())\n",
    "            \n",
    "            num_train = perm.numel() - num_val - num_test\n",
    "\n",
    "            if num_train <= 0:\n",
    "                raise ValueError(\"Insufficient number of edges for training\")\n",
    "\n",
    "            train_edges = perm[:num_train]\n",
    "            val_edges = perm[num_train:num_train + num_val]\n",
    "            test_edges = perm[num_train + num_val:]\n",
    "            train_val_edges = perm[:num_train + num_val]\n",
    "            \n",
    "            num_disjoint = self.disjoint_train_ratio\n",
    "            if isinstance(num_disjoint, float):\n",
    "                num_disjoint = int(num_disjoint * train_edges.numel())\n",
    "            if num_train - num_disjoint <= 0:\n",
    "                raise ValueError(\"Insufficient number of edges for training\")\n",
    "\n",
    "            # Create data splits:\n",
    "            self._split(train_store, train_edges[num_disjoint:], is_undirected,\n",
    "                        rev_edge_type)\n",
    "            self._split(val_store, train_edges, is_undirected, rev_edge_type)\n",
    "            self._split(test_store, train_val_edges, is_undirected,\n",
    "                        rev_edge_type)\n",
    "\n",
    "            # Create negative samples:\n",
    "            num_neg_train = 0\n",
    "            if self.add_negative_train_samples:\n",
    "                if num_disjoint > 0:\n",
    "                    num_neg_train = int(num_disjoint * self.neg_sampling_ratio)\n",
    "                else:\n",
    "                    num_neg_train = int(num_train * self.neg_sampling_ratio)\n",
    "            num_neg_val = int(num_val * self.neg_sampling_ratio)\n",
    "            num_neg_test = int(num_test * self.neg_sampling_ratio)\n",
    "\n",
    "            num_neg = num_neg_train + num_neg_val + num_neg_test\n",
    "\n",
    "            size = store.size()\n",
    "            if store._key is None or store._key[0] == store._key[-1]:\n",
    "                size = size[0]\n",
    "            neg_edge_index = negative_sampling(edge_index, size,\n",
    "                                               num_neg_samples=num_neg,\n",
    "                                               method='sparse')\n",
    "\n",
    "            # Adjust ratio if not enough negative edges exist\n",
    "            if neg_edge_index.size(1) < num_neg:\n",
    "                num_neg_found = neg_edge_index.size(1)\n",
    "                ratio = num_neg_found / num_neg\n",
    "                warnings.warn(\n",
    "                    f\"There are not enough negative edges to satisfy \"\n",
    "                    \"the provided sampling ratio. The ratio will be \"\n",
    "                    f\"adjusted to {ratio:.2f}.\")\n",
    "                num_neg_train = int((num_neg_train / num_neg) * num_neg_found)\n",
    "                num_neg_val = int((num_neg_val / num_neg) * num_neg_found)\n",
    "                num_neg_test = num_neg_found - num_neg_train - num_neg_val\n",
    "\n",
    "            # Create labels:\n",
    "            if num_disjoint > 0:\n",
    "                train_edges = train_edges[:num_disjoint]\n",
    "            self._create_label(\n",
    "                store,\n",
    "                train_edges,\n",
    "                neg_edge_index[:, num_neg_val + num_neg_test:],\n",
    "                out=train_store,\n",
    "            )\n",
    "            self._create_label(\n",
    "                store,\n",
    "                val_edges,\n",
    "                neg_edge_index[:, :num_neg_val],\n",
    "                out=val_store,\n",
    "            )\n",
    "            self._create_label(\n",
    "                store,\n",
    "                test_edges,\n",
    "                neg_edge_index[:, num_neg_val:num_neg_val + num_neg_test],\n",
    "                out=test_store,\n",
    "            )\n",
    "\n",
    "        return train_data, val_data, test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b7f754f-e5c1-4d8f-ae44-aa60951c1410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  \u001b[1mplayer\u001b[0m={\n",
      "    node_id=[36819],\n",
      "    x=[36819, 223]\n",
      "  },\n",
      "  \u001b[1mclub\u001b[0m={ node_id=[1269] },\n",
      "  \u001b[1m(player, plays_for, club)\u001b[0m={\n",
      "    edge_index=[2, 36819],\n",
      "    attr=[36819, 29]\n",
      "  },\n",
      "  \u001b[1m(club, plays_match_against, club)\u001b[0m={\n",
      "    edge_index=[2, 23740],\n",
      "    edge_label=[23740, 15]\n",
      "  },\n",
      "  \u001b[1m(club, rev_plays_for, player)\u001b[0m={\n",
      "    edge_index=[2, 36819],\n",
      "    attr=[36819, 29]\n",
      "  }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "data = HeteroData()\n",
    "\n",
    "# Save node indices:\n",
    "data[\"player\"].node_id = torch.arange(len(unique_player_id))\n",
    "data[\"club\"].node_id = torch.arange(len(unique_club_id))\n",
    "\n",
    "# Add the node features and edge indices:\n",
    "data[\"player\"].x = player_feat\n",
    "data[\"player\", \"plays_for\", \"club\"].edge_index = edge_index_player_to_club\n",
    "data[\"player\", \"plays_for\", \"club\"].attr = player_club_position\n",
    "data[\"club\", \"plays_match_against\", \"club\"].edge_index = edge_index_club_to_club\n",
    "data[\"club\", \"plays_match_against\", \"club\"].edge_label = match_feat\n",
    "\n",
    "\n",
    "# We also need to make sure to add the reverse edges from clubs to players\n",
    "# in order to let a GNN be able to pass messages in both directions.\n",
    "# We can leverage the `T.ToUndirected()` transform for this from PyG:\n",
    "data = T.ToUndirected()(data)\n",
    "print(data)\n",
    "\n",
    "assert data.node_types == [\"player\", \"club\"]\n",
    "assert data.edge_types == [(\"player\", \"plays_for\", \"club\"),\n",
    "                           (\"club\", \"plays_match_against\", \"club\"),\n",
    "                           (\"club\", \"rev_plays_for\", \"player\")]\n",
    "assert data[\"player\"].num_nodes == 36819\n",
    "assert data[\"player\"].num_features == 223\n",
    "assert data[\"club\"].num_nodes == 1269\n",
    "assert data[\"club\"].num_features == 0\n",
    "assert data[\"player\", \"plays_for\", \"club\"].num_edges == 36819\n",
    "assert data[\"club\", \"rev_plays_for\", \"player\"].num_edges == 36819\n",
    "assert data[\"club\", \"plays_match_against\", \"club\"].num_edges == 23740\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8dd33b0-763f-4236-8bfd-0bd85b47ca5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_club_id = unique_club_id[unique_club_id.clubId==\"22_1\"][\"mappedID\"].iloc[0]\n",
    "train_mask = data[\"plays_match_against\"].edge_index < cutoff_club_id\n",
    "\n",
    "num_train_nodes = train_mask.sum(axis=1).numpy()[0]\n",
    "num_val_nodes = int((data[\"plays_match_against\"].num_edges - num_train_nodes) / 2)\n",
    "num_test_nodes = data[\"plays_match_against\"].num_edges - num_train_nodes - num_val_nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37744f47-7d7c-4784-8e09-eebb437f7290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(HeteroData(\n",
       "   \u001b[1mplayer\u001b[0m={\n",
       "     node_id=[36819],\n",
       "     x=[36819, 223]\n",
       "   },\n",
       "   \u001b[1mclub\u001b[0m={ node_id=[1269] },\n",
       "   \u001b[1m(player, plays_for, club)\u001b[0m={\n",
       "     edge_index=[2, 36819],\n",
       "     attr=[36819, 29]\n",
       "   },\n",
       "   \u001b[1m(club, plays_match_against, club)\u001b[0m={\n",
       "     edge_index=[2, 13347],\n",
       "     edge_label=[5719, 15],\n",
       "     edge_label_index=[2, 5719]\n",
       "   },\n",
       "   \u001b[1m(club, rev_plays_for, player)\u001b[0m={\n",
       "     edge_index=[2, 36819],\n",
       "     attr=[36819, 29]\n",
       "   }\n",
       " ),\n",
       " HeteroData(\n",
       "   \u001b[1mplayer\u001b[0m={\n",
       "     node_id=[36819],\n",
       "     x=[36819, 223]\n",
       "   },\n",
       "   \u001b[1mclub\u001b[0m={ node_id=[1269] },\n",
       "   \u001b[1m(player, plays_for, club)\u001b[0m={\n",
       "     edge_index=[2, 36819],\n",
       "     attr=[36819, 29]\n",
       "   },\n",
       "   \u001b[1m(club, plays_match_against, club)\u001b[0m={\n",
       "     edge_index=[2, 19066],\n",
       "     edge_label=[4674, 15],\n",
       "     edge_label_index=[2, 4674]\n",
       "   },\n",
       "   \u001b[1m(club, rev_plays_for, player)\u001b[0m={\n",
       "     edge_index=[2, 36819],\n",
       "     attr=[36819, 29]\n",
       "   }\n",
       " ),\n",
       " HeteroData(\n",
       "   \u001b[1mplayer\u001b[0m={\n",
       "     node_id=[36819],\n",
       "     x=[36819, 223]\n",
       "   },\n",
       "   \u001b[1mclub\u001b[0m={ node_id=[1269] },\n",
       "   \u001b[1m(player, plays_for, club)\u001b[0m={\n",
       "     edge_index=[2, 36819],\n",
       "     attr=[36819, 29]\n",
       "   },\n",
       "   \u001b[1m(club, plays_match_against, club)\u001b[0m={\n",
       "     edge_index=[2, 21403],\n",
       "     edge_label=[4674, 15],\n",
       "     edge_label_index=[2, 4674]\n",
       "   },\n",
       "   \u001b[1m(club, rev_plays_for, player)\u001b[0m={\n",
       "     edge_index=[2, 36819],\n",
       "     attr=[36819, 29]\n",
       "   }\n",
       " ))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split data in train, validate and test sets\n",
    "\n",
    "transform = LinkSplit(\n",
    "    num_val=num_val_nodes,\n",
    "    num_test=num_test_nodes,\n",
    "    key=\"edge_label\",\n",
    "    edge_types=\"plays_match_against\",\n",
    "    add_negative_train_samples=False,\n",
    "    disjoint_train_ratio=0.3\n",
    ")\n",
    "train_data, val_data, test_data = transform(data)\n",
    "\n",
    "train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24fd4b8e-02c3-45a2-ab2f-4e35565d41f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_data, \"train_data.pt\")\n",
    "torch.save(val_data, \"val_data.pt\")\n",
    "torch.save(test_data, \"test_data.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7c7e7c-1da5-4e7f-a6de-8d424bae1c20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
